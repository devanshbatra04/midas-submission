{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AwS9wf71cuCi"
   },
   "source": [
    "Mount google drive and copy and unzip the meld dataset.\n",
    "\n",
    "Also install the python_speech_features library used for extracting mfcc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ln_QFozxmmG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KQLgInKvxn7j"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/My\\ Drive/meld/emotion.zip .\n",
    "!unzip emotion.zip\n",
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "buPf-b72c7BR"
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LvQS0xC9xeGy"
   },
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I-Clp056gfT8"
   },
   "source": [
    "These 2 large files are removed and not used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-OWxWoH5FB0"
   },
   "outputs": [],
   "source": [
    "!rm meld/train/disgust/MEL_dia220_utt0_negative_DIS.wav\n",
    "!rm meld/val/happy/MEL_dia38_utt4_negative_HAP.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGrpA2AqdAI6"
   },
   "source": [
    "set pytorch device to gpu if available otherwise to cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9K68RHuoxeG9"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCVTf5NcdOl0"
   },
   "source": [
    "get class(emotions) labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDtXgsNyxeHE"
   },
   "outputs": [],
   "source": [
    "train_folder = './meld/train/'\n",
    "valid_folder = './meld/val/'\n",
    "classes = [x[0].split('/')[-1] for x in os.walk(train_folder) if x[0].split('/')[-1] != '']\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvHtML5vdT_K"
   },
   "source": [
    "Used the default values of the mfcc function to get numcep(13) no of features from a 25ms(winlen) long sound windows sampled at a step of 10ms(winstep). \n",
    "\n",
    "The number of mfcc features used are 26 and they are reduced to 13 features by discrete cosine reduction to remove corelation.\n",
    "\n",
    "The sample rate is reduced to 16000 (this will capture sounds upto 8000 Hz).\n",
    "\n",
    "```\n",
    "def mfcc(signal, samplerate=16000, winlen=0.025, winstep=0.01,numcep=13, nfilt=26, nfft=512)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cwSIZRl-xeHI"
   },
   "outputs": [],
   "source": [
    "def get_mfcc_features(file):\n",
    "    rate, signal = wavfile.read(file)\n",
    "    return mfcc(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDpOLrq3gGnE"
   },
   "source": [
    "mfcc features corresponding to each audio file in train and valid set are stored train_feature_dict and valid_feature_dict respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ovpb9Z59xeHO"
   },
   "outputs": [],
   "source": [
    "train_feature_dict = {}\n",
    "\n",
    "for c in classes:\n",
    "    files = [x for x in os.listdir(train_folder + c)]\n",
    "  for file in files:\n",
    "    train_feature_dict[file] = get_mfcc_features(train_folder + c + \"/\" + file)\n",
    "\n",
    "valid_feature_dict = {}\n",
    "for c in classes:\n",
    "  files = [x for x in os.listdir(valid_folder + c)]\n",
    "  for file in files:\n",
    "    valid_feature_dict[file] = get_mfcc_features(valid_folder + c + \"/\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tOTWlaIwxeHS",
    "outputId": "c4918a96-b235-4196-946a-2c27107cc1c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7353\n",
      "829\n"
     ]
    }
   ],
   "source": [
    "print(len(train_feature_dict))\n",
    "print(len(valid_feature_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fbvER7OMhMhO"
   },
   "source": [
    "# Normalise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F31MQzschAzh"
   },
   "source": [
    "Minimum and Maximum of the 13 features are calculated for the entire dataset. Mean and Standard Deviation is also calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "wk22Io0_OojZ",
    "outputId": "be65fe52-8f02-4ad0-91a5-f79d36470141"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4662482.0\n",
      "[ 15.82453726   1.36319049  -8.39165081  -9.98267385   5.67570697\n",
      "  -9.23731186  -6.76188475  -0.0252859  -12.45081199  -0.9668685\n",
      " -11.45884017  -1.75013094  -4.48973996]\n",
      "[23.94766958 35.47760648 32.407666   82.12595251 85.63384494 62.8985791\n",
      " 61.30809941 79.46652656 59.85923447 70.58265384 43.68436301 58.37647754\n",
      " 54.0187414 ]\n",
      "[-36.04365339 -58.63459727 -57.64907143 -80.63907682 -81.08503093\n",
      " -85.38878632 -75.72724483 -76.89883101 -92.74224276 -90.46006047\n",
      " -75.38062188 -70.24483321 -79.46963393]\n",
      "[ 2.71048281 10.95529956  9.06456857 17.6678814  14.01453595 14.85012859\n",
      " 11.58754407 13.94876534 13.54238226 13.30045671 10.39980429 10.72943595\n",
      " 10.62327105]\n"
     ]
    }
   ],
   "source": [
    "feature_sum = [0.0 for _ in range(13)]\n",
    "total = 0.0\n",
    "\n",
    "feature_max_value = [-100000.0 for _ in range(13)]\n",
    "feature_min_value = [100000.0 for _ in range(13)]\n",
    "\n",
    "for key, val in train_feature_dict.items():\n",
    "  total += val.shape[0]\n",
    "  feature_sum += val.sum(axis = 0)\n",
    "  feature_max_value = np.maximum(val.max(axis=0), feature_max_value)\n",
    "  feature_min_value = np.minimum(val.min(axis=0), feature_min_value)\n",
    "\n",
    "mean = feature_sum / total\n",
    "print(total)\n",
    "print(mean)\n",
    "print(feature_max_value)\n",
    "print(feature_min_value)\n",
    "variance = [0.0 for _ in range(13)]\n",
    "square_diff_sum = 0.0\n",
    "for key, val in train_feature_dict.items():\n",
    "  square_diff_sum += ((val - mean)**2).sum(axis=0)\n",
    "\n",
    "standard_deviation = (square_diff_sum / total)**0.5\n",
    "print(standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CdnTKY-OhbcK"
   },
   "source": [
    "Normalising the mfcc features and converting them to numbers between 0 to 1\n",
    "\n",
    "train_feature_dict_normalised stores the training features\n",
    "valid_feature_dict_normalised stores the valid features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KaReJRUIQU9Z"
   },
   "outputs": [],
   "source": [
    "train_feature_dict_normalised = {}\n",
    "for key, val in train_feature_dict.items():\n",
    "  train_feature_dict_normalised[key] = (val - feature_min_value)/(feature_max_value-feature_min_value)\n",
    "\n",
    "valid_feature_dict_normalised = {}\n",
    "for key, val in valid_feature_dict.items():\n",
    "  valid_feature_dict_normalised[key] = (val - feature_min_value)/(feature_max_value-feature_min_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vSACWF-xiuod"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGXyK5uXivyZ"
   },
   "source": [
    "# Saving and loading the mfcc features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vRQQMiLaH9Z"
   },
   "outputs": [],
   "source": [
    "with open('train_mfcc_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_feature_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('valid_mfcc_features.pickle', 'wb') as handle:\n",
    "    pickle.dump(valid_feature_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUgrRECdak7s"
   },
   "outputs": [],
   "source": [
    "with open('train_mfcc_features_normalised.pickle', 'wb') as handle:\n",
    "    pickle.dump(train_feature_dict_normalised, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('valid_mfcc_features_normalised.pickle', 'wb') as handle:\n",
    "    pickle.dump(valid_feature_dict_normalised, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TZ-xrY73xeHY"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_feature_dict = {}\n",
    "with open('train_mfcc_features.pickle', 'rb') as handle:\n",
    "    train_feature_dict = pickle.load(handle)\n",
    "\n",
    "valid_feature_dict = {}\n",
    "with open('valid_mfcc_features_normalised.pickle', 'rb') as handle:\n",
    "    valid_feature_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biLBtSfGi3_V"
   },
   "source": [
    "# One hot encodding the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "gqYpKSOcxeHb",
    "outputId": "3e8f475a-6e99-4b0a-e9b1-4cac46d43d4d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FName</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>MEL_dia548_utt0_positive_HAP.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>MEL_dia499_utt0_positive_HAP.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6618</th>\n",
       "      <td>MEL_dia796_utt5_negative_FEA.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>MEL_dia575_utt1_neutral_NEU.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5163</th>\n",
       "      <td>MEL_dia1035_utt4_neutral_NEU.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 FName  Label\n",
       "556   MEL_dia548_utt0_positive_HAP.wav      0\n",
       "574   MEL_dia499_utt0_positive_HAP.wav      0\n",
       "6618  MEL_dia796_utt5_negative_FEA.wav      3\n",
       "5300   MEL_dia575_utt1_neutral_NEU.wav      1\n",
       "5163  MEL_dia1035_utt4_neutral_NEU.wav      1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_dict = {}\n",
    "for c in classes:\n",
    "  train_file_dict.update({x : classes.index(c) for x in os.listdir(train_folder + c)})\n",
    "train_file_df = pd.DataFrame(list(train_file_dict.items()), columns=['FName', 'Label'])\n",
    "train_file_df = shuffle(train_file_df)\n",
    "train_file_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sC14lDsKpwPy",
    "outputId": "c61c60c9-2655-42d0-d89b-7195e764962f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FName</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>MEL_dia13_utt1_negative_NEU.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>MEL_dia37_utt3_negative_FEA.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>MEL_dia84_utt5_negative_SAD.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>MEL_dia55_utt13_positive_HAP.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>MEL_dia62_utt11_neutral_NEU.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                FName  Label\n",
       "494   MEL_dia13_utt1_negative_NEU.wav      1\n",
       "725   MEL_dia37_utt3_negative_FEA.wav      3\n",
       "751   MEL_dia84_utt5_negative_SAD.wav      4\n",
       "160  MEL_dia55_utt13_positive_HAP.wav      0\n",
       "486   MEL_dia62_utt11_neutral_NEU.wav      1"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_file_dict = {}\n",
    "for c in classes:\n",
    "  valid_file_dict.update({x : classes.index(c) for x in os.listdir(valid_folder + c)})\n",
    "valid_file_df = pd.DataFrame(list(valid_file_dict.items()), columns=['FName', 'Label'])\n",
    "valid_file_df = shuffle(valid_file_df)\n",
    "valid_file_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cc0fTvXli-Ji"
   },
   "source": [
    "# Creating PyTorch Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8nXvrkPjFZh"
   },
   "source": [
    "As the audio files are of different sizes the number of windows sampled for mfcc features are different. To make them of same size for making bacthes, the train and valid features are padded with zeros at the end.\n",
    "\n",
    "The maximum sequence length was little less than 10000.\n",
    "\n",
    "\n",
    "```\n",
    "torch.cat([torch.tensor(self.feature_dict[file], dtype=torch.float64), torch.zeros((max-self.feature_dict[file].shape[0], 13), dtype=torch.float64)]\n",
    "```\n",
    "This line append zeros to the end of the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6soqnKaexeHg"
   },
   "outputs": [],
   "source": [
    "max = 10000\n",
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self, df, feature_dict):\n",
    "        self.file_df = df\n",
    "        self.feature_dict = feature_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file, label = self.file_df.iloc[index,:]\n",
    "        features = torch.cat([torch.tensor(self.feature_dict[file], dtype=torch.float64), torch.zeros((max-self.feature_dict[file].shape[0], 13), dtype=torch.float64)], dim=0).float()\n",
    "        return features, torch.tensor(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiehY5AckosA"
   },
   "source": [
    "Batch size is taken as 32\n",
    "\n",
    "The train and valid dataloader are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vh7Z01dPxeHj"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_ds = SpeechDataset(train_file_df, train_feature_dict_normalised)\n",
    "valid_ds = SpeechDataset(valid_file_df, valid_feature_dict_normalised)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=batch_size, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yp6v4AAMk75s"
   },
   "source": [
    "# Model\n",
    "\n",
    "The input features are passed through stacked LSTM of 8 layers.\n",
    "The first LSTM layer is 13x64, the rest 7 are 64x64.\n",
    "\n",
    "Then at the end of the sequence all the hidden layers of LSTM (8 * 64) are fed into the fully connected Linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "5Djp4I7axeHn",
    "outputId": "1c802a0b-41e1-4aa6-e324-6256c25ef377"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (lstm): LSTM(13, 64, num_layers=8, batch_first=True)\n",
       "  (relu): ReLU()\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=16, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(13, 64, 8, batch_first=True)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 5),\n",
    "        )\n",
    "        self.hidden = (torch.zeros(8, batch_size, 64).float().cuda(), torch.zeros(8, batch_size, 64).float().cuda())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        _, hidden = self.lstm(inputs, self.hidden)\n",
    "        hid = (hidden[0].clone().detach().permute(1, 0, 2)).flatten(start_dim=1)\n",
    "        output = self.linear_layers(hid)\n",
    "        return output\n",
    "\n",
    "model = Net()\n",
    "model.cuda()\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "alzKSn4qlwtJ"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUKf8SNLlziv"
   },
   "source": [
    "The cross entroy loss is chosen as the loss function\n",
    "\n",
    "Stochastic Gradient Descent optimiser with learning rate 0.001 and momentum 0.8 is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYpOgo4vxeHr"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(model.parameters(), lr = 0.001, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UDiQA-6pxeHv",
    "outputId": "bfb29597-627e-4fc3-fa65-4a63179a8d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Epoch  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd540a872324cc3a5d1039fe7af45cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=229), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.3670663130855978  accuracy :  56.18176855895196\n",
      "training accuracy :  56.18176855895196 %\n",
      "training loss :  1.3670663130855978\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd95291798f4c0b894255f0831118bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "validation accuracy :  62.125 %\n",
      "validation loss :  1.2597495317459106\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Epoch  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24b7b2582c9436f94e346793a4c1985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=229), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.188852322674214  accuracy :  62.45906113537117\n",
      "training accuracy :  62.45906113537117 %\n",
      "training loss :  1.188852322674214\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02eaf941e584cc9a07ac5844ba79555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "validation accuracy :  62.25000000000001 %\n",
      "validation loss :  1.1427534413337708\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Epoch  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108460a36bf043198e17c9366600e9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=229), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.112812109909724  accuracy :  62.472707423580786\n",
      "training accuracy :  62.472707423580786 %\n",
      "training loss :  1.112812109909724\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0efe6386de64c31ab48da03154fbc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "validation accuracy :  62.625 %\n",
      "validation loss :  1.0981243395805358\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Epoch  4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c64048c9f64d78900bdc25a3f37061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=229), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.0870932533230844  accuracy :  62.41812227074236\n",
      "training accuracy :  62.41812227074236 %\n",
      "training loss :  1.0870932533230844\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00f962ee6f6f46bc9a2701e8db5549bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "validation accuracy :  62.5 %\n",
      "validation loss :  1.0825830602645874\n",
      "\n",
      "\n",
      "\n",
      "****************************************************************************************************\n",
      "Epoch  5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2405945a899145b6be4fc0579a12da70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=229), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  1.076166417661192  accuracy :  62.472707423580786\n",
      "training accuracy :  62.472707423580786 %\n",
      "training loss :  1.076166417661192\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccf653f39ff41708aaccf8046e0b6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=25), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "validation accuracy :  63.0 %\n",
      "validation loss :  1.0668337988853454\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(\"*\" * 100)\n",
    "    print(\"Epoch \", epoch+1)\n",
    "\n",
    "    train_loss = 0.0\n",
    "    train_total = 0\n",
    "    train_correct = 0\n",
    "    model.train()\n",
    "    with tqdm_notebook(total=len(train_loader)) as progress_bar:\n",
    "      for features, label in iter(train_loader):\n",
    "          features, label = features.cuda(), label.cuda()\n",
    "          optimiser.zero_grad()\n",
    "          output = model(features)\n",
    "          train_correct += (output.argmax(1) == label).float().sum().item()\n",
    "          train_total += features.shape[0]\n",
    "          loss = loss_fn(output, label)\n",
    "          loss.backward()\n",
    "          train_loss += loss.item()*batch_size\n",
    "          optimiser.step()\n",
    "          progress_bar.update(1)\n",
    "          print('\\rloss : ', train_loss/train_total, \" accuracy : \", train_correct/train_total*100, end = \"\")\n",
    "\n",
    "    print(\"\\rtraining accuracy : \", train_correct/train_total*100, \"%\")\n",
    "    print(\"training loss : \", train_loss/train_total)\n",
    "    print('\\n\\n')\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    valid_total = 0\n",
    "    valid_correct = 0\n",
    "    model.eval()\n",
    "    with tqdm_notebook(total=len(valid_loader)) as progress_bar:\n",
    "      for features, label in iter(valid_loader):\n",
    "          features, label = features.cuda(), label.cuda()\n",
    "          output = model(features)\n",
    "          valid_correct += (output.argmax(1) == label).float().sum().item()\n",
    "          valid_total += features.shape[0]\n",
    "          loss = loss_fn(output, label)\n",
    "          valid_loss += loss.item()*batch_size\n",
    "          progress_bar.update(1)\n",
    "\n",
    "    print(\"\\rvalidation accuracy : \", valid_correct/valid_total*100, \"%\")\n",
    "    print(\"validation loss : \", valid_loss/valid_total)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vn3poBX5mJkU"
   },
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5vfQ9Xu6zmNe"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mffcc-features-normalised-momentum.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Speech Emotion Recognition MFCC-features-normalise-momentum.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
